from random import uniform
import matplotlib.pyplot as plt
import numpy as np

def mse(outputs, targets):
    error = 0
    for i, output in enumerate(outputs):
        error += (output - targets[i]) ** 2
    return error / len(outputs)

def r_squared(outputs, targets):
    """Коэффициент детерминации R²"""
    ss_res = sum((t - o) ** 2 for t, o in zip(targets, outputs))
    ss_tot = sum((t - np.mean(targets)) ** 2 for t in targets)
    return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

class LinearRegression:
    def __init__(self, features_num):
        # Инициализация весов небольшими случайными значениями
        # Последний вес - bias (свободный член)
        self.weights = [uniform(-1, 1) for _ in range(features_num + 1)]
        self.features_num = features_num
        
    def forward(self, input_features):
        """Прямой проход: вычисление прогноза"""
        output = 0
        for i, feature in enumerate(input_features):
            output += self.weights[i] * feature
        output += self.weights[-1]  # bias
        return output
    
    def train(self, inp, output, target, samples_num, lr):
        """Одно обновление весов методом градиентного спуска"""
        for j in range(self.features_num):
            self.weights[j] -= lr * (2 / samples_num) * (output - target) * inp[j]
        
        # Обновление bias
        self.weights[-1] -= lr * (2 / samples_num) * (output - target)
    
    def fit(self, inputs, targets, epochs=1000, lr=0.01, verbose=True):
        """Обучение модели"""
        errors = []
        r_squared_values = []
        
        for epoch in range(epochs):
            outputs = []
            
            for i, inp in enumerate(inputs):
                output = self.forward(inp)
                outputs.append(output)
                self.train(inp, output, targets[i], len(inputs), lr)
            
            error = mse(outputs, targets)
            errors.append(error)
            r2 = r_squared(outputs, targets)
            r_squared_values.append(r2)
            
            if verbose and (epoch % 100 == 0 or epoch == epochs - 1):
                print(f"Эпоха: {epoch:4d}, MSE: {error:.6f}, R²: {r2:.4f}")
        
        return errors, r_squared_values
    
    def predict(self, inputs):
        """Прогнозирование для новых данных"""
        predictions = []
        for inp in inputs:
            predictions.append(self.forward(inp))
        return predictions
    
    def get_equation(self):
        """Получение уравнения регрессии в читаемом виде"""
        equation = f"Y = {self.weights[-1]:.4f}"
        for i in range(self.features_num):
            sign = "+" if self.weights[i] >= 0 else "-"
            equation += f" {sign} {abs(self.weights[i]):.4f}*X{i+1}"
        return equation

def normalize_data(data):
    """Нормализация данных (z-score normalization)"""
    mean = np.mean(data)
    std = np.std(data)
    if std == 0:
        return [0 for _ in data]
    return [(x - mean) / std for x in data]

def analyze_significance(model, inputs, targets):
    """Анализ значимости факторов"""
    print("\n" + "="*60)
    print("АНАЛИЗ ЗНАЧИМОСТИ ФАКТОРОВ")
    print("="*60)
    
    # Предсказания модели
    predictions = model.predict(inputs)
    
    # Суммы квадратов
    ss_total = sum((t - np.mean(targets)) ** 2 for t in targets)
    ss_residual = sum((t - p) ** 2 for t, p in zip(targets, predictions))
    ss_regression = ss_total - ss_residual
    
    # Степени свободы
    n = len(targets)
    k = model.features_num
    
    # Средние квадраты
    ms_regression = ss_regression / k
    ms_residual = ss_residual / (n - k - 1)
    
    # F-статистика
    f_statistic = ms_regression / ms_residual if ms_residual != 0 else 0
    
    # Стандартные ошибки коэффициентов
    print(f"Уравнение регрессии: {model.get_equation()}")
    print(f"\nОбщая сумма квадратов (SST): {ss_total:.4f}")
    print(f"Объясненная сумма квадратов (SSR): {ss_regression:.4f}")
    print(f"Остаточная сумма квадратов (SSE): {ss_residual:.4f}")
    print(f"F-статистика: {f_statistic:.4f}")
    
    # Коэффициенты детерминации
    r2 = r_squared(predictions, targets)
    r2_adj = 1 - (1 - r2) * (n - 1) / (n - k - 1) if n > k + 1 else 0
    
    print(f"\nКоэффициент детерминации R²: {r2:.4f}")
    print(f"Скорректированный R²: {r2_adj:.4f}")
    
    # Оценка значимости каждого фактора
    print("\nОЦЕНКА ВКЛАДА ФАКТОРОВ:")
    for i in range(model.features_num):
        # Простая оценка важности на основе абсолютного значения веса
        importance = abs(model.weights[i]) / sum(abs(w) for w in model.weights[:-1])
        factor_name = "X2 (осужденные)" if i == 0 else "X4 (мигранты)"
        print(f"{factor_name}: вес = {model.weights[i]:.4f}, относительная важность = {importance:.2%}")

def plot_results(targets, predictions, errors_history, r2_history):
    """Визуализация результатов"""
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # График 1: Фактические vs предсказанные значения
    axes[0, 0].scatter(targets, predictions, alpha=0.7)
    axes[0, 0].plot([min(targets), max(targets)], [min(targets), max(targets)], 
                   'r--', label='Идеальная линия')
    axes[0, 0].set_xlabel('Фактические значения Y')
    axes[0, 0].set_ylabel('Предсказанные значения Y')
    axes[0, 0].set_title('Фактические vs Предсказанные значения')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # График 2: Ошибки по эпохам
    axes[0, 1].plot(errors_history, 'b-', linewidth=2)
    axes[0, 1].set_xlabel('Эпоха')
    axes[0, 1].set_ylabel('MSE')
    axes[0, 1].set_title('Сходимость MSE')
    axes[0, 1].grid(True, alpha=0.3)
    axes[0, 1].set_yscale('log')
    
    # График 3: R² по эпохам
    axes[1, 0].plot(r2_history, 'g-', linewidth=2)
    axes[1, 0].set_xlabel('Эпоха')
    axes[1, 0].set_ylabel('R²')
    axes[1, 0].set_title('Изменение коэффициента детерминации R²')
    axes[1, 0].grid(True, alpha=0.3)
    
    # График 4: Остатки
    residuals = [t - p for t, p in zip(targets, predictions)]
    axes[1, 1].scatter(predictions, residuals, alpha=0.7)
    axes[1, 1].axhline(y=0, color='r', linestyle='--')
    axes[1, 1].set_xlabel('Предсказанные значения')
    axes[1, 1].set_ylabel('Остатки')
    axes[1, 1].set_title('Анализ остатков')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def main():
    # Данные из файла Cheruh.csv
    # Формат: Y (преступления); X2 (осужденные); X4 (мигранты)
    data = [
        [60, 35, 31],
        [54, 28, 22],
        [65, 35, 27],
        [85, 45, 42],
        [68, 36, 33],
        [95, 50, 45],
        [53, 29, 27],
        [67, 36, 35],
        [61, 33, 33],
        [59, 32, 27],
        [74, 39, 37],
        [58, 31, 21],
        [43, 24, 19],
        [76, 40, 33],
        [80, 42, 41],
        [72, 38, 37],
        [93, 49, 41],
        [56, 30, 37],
        [74, 39, 42],
        [34, 19, 17],
        [54, 28, 33],
        [39, 41, 21],
        [61, 15, 45],
        [40, 15, 27]
    ]
    
    # Разделение данных на переменные
    Y = [row[0] for row in data]      # Количество преступлений
    X2 = [row[1] for row in data]     # Количество осужденных
    X4 = [row[2] for row in data]     # Численность мигрантов
    
    print("АНАЛИЗ МНОЖЕСТВЕННОЙ ЛИНЕЙНОЙ РЕГРЕССИИ")
    print("="*60)
    print(f"Количество наблюдений: {len(Y)}")
    print(f"Y (преступления): среднее = {np.mean(Y):.2f}, std = {np.std(Y):.2f}")
    print(f"X2 (осужденные): среднее = {np.mean(X2):.2f}, std = {np.std(X2):.2f}")
    print(f"X4 (мигранты): среднее = {np.mean(X4):.2f}, std = {np.std(X4):.2f}")
    
    # Нормализация данных (рекомендуется для градиентного спуска)
    Y_norm = normalize_data(Y)
    X2_norm = normalize_data(X2)
    X4_norm = normalize_data(X4)
    
    # Подготовка данных для обучения
    inputs = [[x2, x4] for x2, x4 in zip(X2_norm, X4_norm)]
    targets = Y_norm
    
    print("\n" + "="*60)
    print("НАЧАЛО ОБУЧЕНИЯ МОДЕЛИ")
    print("="*60)
    
    # Создание и обучение модели
    model = LinearRegression(features_num=2)
    errors_history, r2_history = model.fit(
        inputs, 
        targets, 
        epochs=2000, 
        lr=0.05,  # меньшая скорость обучения для стабильности
        verbose=True
    )
    
    # Прогнозирование
    predictions_norm = model.predict(inputs)
    
    # Денормализация для интерпретации
    Y_mean = np.mean(Y)
    Y_std = np.std(Y)
    predictions = [p * Y_std + Y_mean for p in predictions_norm]
    
    print("\n" + "="*60)
    print("РЕЗУЛЬТАТЫ МОДЕЛИ")
    print("="*60)
    
    # Анализ значимости факторов
    analyze_significance(model, inputs, targets)
    
    # Вывод первых нескольких прогнозов
    print("\nПРИМЕРЫ ПРОГНОЗОВ:")
    print("Индекс | Фактический Y | Прогноз Y | Ошибка")
    for i in range(min(8, len(Y))):
        error = Y[i] - predictions[i]
        print(f"{i:6d} | {Y[i]:13.2f} | {predictions[i]:10.2f} | {error:8.2f}")
    
    # Итоговая статистика
    final_mse = mse(predictions, Y)
    final_r2 = r_squared(predictions, Y)
    
    print(f"\nИТОГОВАЯ СТАТИСТИКА:")
    print(f"Среднеквадратичная ошибка (MSE): {final_mse:.4f}")
    print(f"Корень из MSE (RMSE): {np.sqrt(final_mse):.4f}")
    print(f"Коэффициент детерминации R²: {final_r2:.4f}")
    
    # Вывод уравнений регрессии
    print("\n" + "="*60)
    print("УРАВНЕНИЯ РЕГРЕССИИ:")
    print("="*60)
    print("В нормализованных данных:")
    print(model.get_equation())
    
    # Расчет уравнения в исходных данных
    print("\nВ исходных данных (приближенно):")
    # Для преобразования уравнения из нормализованных данных в исходные
    # Y_norm = (Y - mean_Y) / std_Y
    # X2_norm = (X2 - mean_X2) / std_X2
    # X4_norm = (X4 - mean_X4) / std_X4
    
    mean_Y = np.mean(Y)
    std_Y = np.std(Y)
    mean_X2 = np.mean(X2)
    std_X2 = np.std(X2)
    mean_X4 = np.mean(X4)
    std_X4 = np.std(X4)
    
    # Преобразование коэффициентов
    w0_norm = model.weights[-1]  # intercept в нормализованных данных
    w1_norm = model.weights[0]   # коэффициент для X2_norm
    w2_norm = model.weights[1]   # коэффициент для X4_norm
    
    # Преобразование в исходный масштаб
    w1_original = w1_norm * (std_Y / std_X2)
    w2_original = w2_norm * (std_Y / std_X4)
    w0_original = mean_Y - w1_original * mean_X2 - w2_original * mean_X4 + w0_norm * std_Y
    
    print(f"Y = {w0_original:.4f} + {w1_original:.4f}*X2 + {w2_original:.4f}*X4")
    
    # Визуализация
    plot_results(Y, predictions, errors_history, r2_history)
    
    print("\n" + "="*60)
    print("ВЫВОДЫ И ИНТЕРПРЕТАЦИЯ:")
    print("="*60)
    print("1. Модель показывает зависимость количества преступлений (Y)")
    print("   от количества осужденных (X2) и численности мигрантов (X4)")
    print("2. Коэффициент детерминации R² показывает, какая доля дисперсии")
    print("   зависимой переменной объясняется моделью")
    print("3. Значимость факторов оценивается по их вкладу в модель")
    print("4. Анализ остатков помогает проверить допущения модели")
    print("5. Для улучшения модели можно:")
    print("   - Добавить больше факторов")
    print("   - Проверить на мультиколлинеарность")
    print("   - Рассмотреть нелинейные преобразования")
    print("   - Увеличить объем данных")

if __name__ == '__main__':
    main()
